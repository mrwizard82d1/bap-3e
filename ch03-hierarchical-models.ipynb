{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Hierarchical Models",
   "id": "9386980636bf4583"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We previously modelled tips for each day as completely independent of\n",
    "any other day. Perhaps this implicit assumption is not correct. How\n",
    "might we improve our tips model?\n",
    "\n",
    "One idea: a hierarchical model where each day has a **hyper-prior**\n",
    "that allows days to be **simultaneously** independent and related."
   ],
   "id": "1f79ff260820a9f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 Sharing information, sharing priors",
   "id": "97115824a93dfac5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hierarchical models are particularly useful when the data has a\n",
    "natural hierarchy. Some examples are:\n",
    "\n",
    "- Geographical regions (for example, cities, counties, and states)\n",
    "- Students within schools\n",
    "- Patients nested with hospitals\n",
    "- Repeated measurements **on the same** individuals\n",
    "\n",
    "In a hierarchical model, the parameters of the priors are themselves\n",
    "drawn from another (prior) distribution (often called **hyperpriors**).\n",
    "This structure allows groups to be different but also to share\n",
    "information between groups while, at the same time, allowing\n",
    "**differences between groups.**\n",
    "\n"
   ],
   "id": "7f5502e2272c11b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform our typical data science and PyMC imports\n",
    "\n",
    "# Import cytoolz for data manipulation\n",
    "import cytoolz.curried as ctc\n",
    "\n",
    "# Import PyMC and supporting packages\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "import preliz as pz\n",
    "\n",
    "# Import other \"data science\" packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sympy.plotting.experimental_lambdify import experimental_lambdify\n",
    "from torch.utils.model_dump import hierarchical_pickle"
   ],
   "id": "c433b1cbf9f0c21e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Some additional initialization (for consistency)\n",
    "az.style.use('arviz-grayscale')\n",
    "from cycler import cycler\n",
    "default_cycler = cycler(color=[\"#000000\", \"#6a6a6a\", \"#bebebe\", \"#2a2eec\"])\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "plt.rc('figure', dpi=300)\n",
    "\n",
    "# Set a consistent random seed\n",
    "rng = np.random.default_rng(seed=123)"
   ],
   "id": "5a27def215e67a62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 Hierarchical shifts",
   "id": "a2ad7867b9d0b565"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Proteins are molecules formed by 20 units call amino acids. And each\n",
    "amino acid can appear in a protein zero or more times.\n",
    "\n",
    "One way to study proteins is nuclear magnetic resonance. This technique\n",
    "allows us to measure different quantities such as the chemical shift.\n",
    "\n",
    "Suppose we want to compare a theoretical method of computing chemical\n",
    "shifts with experimental observations. This experiment allows us to\n",
    "evaluate the theory.\n",
    "\n",
    "Luckily, someone has already performed both the theoretical calculations\n",
    "and the experiments. We just need to perform the comparison.\n",
    "\n",
    "The data frame, indicated by the variable, `cs_data`, has four columns:\n",
    "\n",
    "- A code that identifies the protein\n",
    "- A second column that names the amino acid\n",
    "- The third column contains the theoretical chemical shift values\n",
    "- The fourth column has the experimental values\n"
   ],
   "id": "5b5207d07ebaf00f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import the data of interest\n",
    "cs_data = pd.read_csv('data/chemical_shifts_theo_exp.csv')\n",
    "cs_data"
   ],
   "id": "f1f0dc4e991db3f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The difference (`diff`) is our measure of interest\n",
    "diff = cs_data.theo - cs_data.exp\n",
    "\n",
    "# Encode the amino acid name as categories\n",
    "cat_encode = pd.Categorical(cs_data['aa']) # amino acid\n",
    "idx = cat_encode.codes\n",
    "\n",
    "# Use the categories as \"coordinates\"\n",
    "coords = {'aa': cat_encode.categories}"
   ],
   "id": "12839dcd2e4f427b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "diff",
   "id": "ae1566db763f993c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now that we have the data, how should we proceed? One option: take the\n",
    "empirical differences and fit a Gaussian or Student's T model. Because\n",
    "amino acids are a \"family,\" it would make sense to assume they are all\n",
    "the same and estimate a single Gaussian for **all** the differences.\n",
    "\n",
    "But one may argue: Is not each amino acid different from all the others?\n",
    "Biologically, yes. Chemically, yes, but I am uncertain how different. If\n",
    "we treat each amino acid differently from all the others, will my model\n",
    "of reality be better than a single model?\n",
    "\n",
    "Here are some of the consequences:\n",
    "\n",
    "| Single model                        | Multiple models                               |\n",
    "|-------------------------------------|-----------------------------------------------|\n",
    "| Our estimates will be more accurate | More detailed analysis but with less accuracy |\n",
    "\n",
    "What should we do?\n",
    "\n",
    "When in doubt, do **everything**! We will build a hierarchical model.\n",
    "This choice allows estimates at a group level with a \"restriction\"\n",
    "that all items belong to a larger group or population.\n",
    "\n",
    "However, to see the difference, we will actually build **two models**.\n",
    "\n",
    "- A non-hierarchical (unpooled) model\n",
    "- A hierarchical model\n",
    "\n",
    "For reference, the unpooled model is essentially the same as our\n",
    "`comparing_groups` model from [chapter 2](./ch02-prog-probabilistically.ipynb)."
   ],
   "id": "da293609e78fb9da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Our non-hierarchical model\n",
    "with pm.Model(coords=coords) as cs_nh: # chemical shifts non-hierarchical\n",
    "    mu = pm.Normal('mu', mu=00, sigma=10, dims='aa')\n",
    "    sigma = pm.HalfNormal('sigma', sigma=10, dims='aa')\n",
    "    y = pm.Normal('y', mu=mu[idx], sigma=sigma[idx], observed=diff)\n",
    "\n",
    "    idata_cs_nh = pm.sample()"
   ],
   "id": "12873c54a172f6ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we will build the hierarchical version of the model.\n",
    "\n",
    "We add **two** hyperpriors:\n",
    "\n",
    "- One for the mean of $\\mu$\n",
    "- One for the standard deviation of $\\mu$\n",
    "\n",
    "We leave $\\sigma$ **without** hyperpriors; that is, we assume that the\n",
    "variance between observed and theoretical values should be unique\n",
    "**for each group.**. This choice is a **modelling choice**. Remember\n",
    "that you may face a problem in which independent variances does not\n",
    "seem reasonable. In this situation, feel free to add a hyperprior\n",
    "for $\\sigma$."
   ],
   "id": "d9029dc0ef92a010"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with pm.Model(coords=coords) as cs_h:\n",
    "    # Hyper priors\n",
    "    mu_mu = pm.Normal('mu_mu', mu=0, sigma=10)\n",
    "    mu_sd = pm.HalfNormal('mu_sd', sigma=10)\n",
    "\n",
    "    # Priors\n",
    "    mu = pm.Normal('mu', mu=mu_mu, sigma=mu_sd, dims='aa')\n",
    "    sigma = pm.HalfNormal('sigma', sigma=10, dims='aa')\n",
    "\n",
    "    # Likelihood\n",
    "    y = pm.Normal('y', mu=mu[idx], sigma=sigma[idx], observed=diff)\n",
    "    idata_cs_h = pm.sample()"
   ],
   "id": "4552fc051c69ef29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pm.model_to_graphviz(cs_nh)",
   "id": "b4df9b78963c81d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pm.model_to_graphviz(cs_h)\n",
   "id": "86d0800bca1d80b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can compare results using the `plot_forest` function of `ArviZ`.\n",
    "We can pass more than one model to this function.\n",
    "\n",
    "Plotting multiple models is useful when we want to compare the values\n",
    "of parameters from different models - like the current example.\n",
    "\n",
    "The plot includes both the 94% HDI and the inter-quartile range. The\n",
    "vertical dashed line is the global mean according to the hierarchical\n",
    "model. This value is close to zero which is expected for theoretical\n",
    "values faithfully representing experimental ones."
   ],
   "id": "39d266457d86cbfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "axes = az.plot_forest(\n",
    "    [idata_cs_nh, idata_cs_h],\n",
    "    model_names=['non-hierarchical', 'hierarchical'],\n",
    "    var_names='mu',\n",
    "    combined=True,\n",
    "    r_hat=False,\n",
    "    ess=False,\n",
    "    figsize=(10, 7),\n",
    "    colors='cycle',\n",
    ")\n",
    "y_lims = axes[0].get_ylim()\n",
    "axes[0].vlines(idata_cs_h.posterior['mu_mu'].mean(),\n",
    "               *y_lims,\n",
    "               color='k',\n",
    "               ls=':')\n",
    "plt.show()"
   ],
   "id": "7243483530f3f91e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The most relevant part of this plot is that the estimates from the\n",
    "hierarchical model are pulled toward the partially pooled mean;\n",
    "equivalently, they are shrunken in comparison to the unpooled estimates.\n",
    "Additionally, the effect is more pronounced for the groups farther away\n",
    "from the mean (such as \"PRO\"). That uncertainty is on par with or\n",
    "smaller than the uncertainty from the non-hierarchical model. The\n",
    "estimates are partially pooled because we have one estimate for each\n",
    "group, but estimates for individual groups restrict each other through\n",
    "the hyperprior. Therefore, we get an intermediate situation between\n",
    "having a single group with all the chemical shifts together and\n",
    "having 20 separate groups, one per amino acid."
   ],
   "id": "9d3f71522201de5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.3 Water quality",
   "id": "937a724be7a5f634"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Suppose we want to study the quality of water in a city. We take samples\n",
    "in a number of neighborhoods.\n",
    "\n",
    "We have two options for analyzing this data:\n",
    "\n",
    "- Study each neighborhood as a **separate** entity\n",
    "- Pool all the neighborhood data together and estimate the water quality\n",
    "for the city as a whole.\n",
    "\n",
    "This procedure is a recurring pattern:\n",
    "\n",
    "- The first option allows a more detailed study of the problem\n",
    "- The second option, because the amount of data is larger, is more accurate.\n",
    "\n",
    "But we have a third option: build a hierarchical model!\n",
    "\n",
    "To learn about hierarchical models in this scenario, we will\n",
    "**simulate data**. The advantage of simulated data is that it allows us\n",
    "to better understand our process (because, in theory, we\n",
    "**know the answer**).\n",
    "\n",
    "In our synthetic scenario, we imagine that:\n",
    "\n",
    "- We collect water from three different regions of the system\n",
    "- We measure the lead content of the collected water\n",
    "- We encode \"safe\" (1 or `True`) and \"unsafe\" (0 or `False`) using\n",
    "recommendations from the World Health Organization.\n",
    "\n",
    "This scenario is a very simple scenario. In a more realistic scenario,\n",
    "we would have a continuous measurement of lead concentrations and\n",
    "probably many more samples.\n",
    "\n",
    "The following code generates our synthetic data."
   ],
   "id": "95e2cc4384f7ec57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate synthetic data\n",
    "N_samples = [30, 30, 30] # number of samples\n",
    "G_samples = [18, 18, 18] # number of good samples\n",
    "group_idx = np.repeat(np.arange(len(N_samples)), N_samples)\n",
    "\n",
    "# Perhaps `cytoolz` might simplify this code\n",
    "data = []\n",
    "for i in range(0, len(N_samples)):\n",
    "    data.extend(np.repeat([1, 0],\n",
    "                          [G_samples[i], N_samples[i] - G_samples[i]]))"
   ],
   "id": "979ed68aa27a3818",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The model for this problem is similar to the model we used for the\n",
    "coin problem except for two important features:\n",
    "\n",
    "- We will define **two** hyperpriors that influence the Beta prior\n",
    "- Instead of setting hyperpriors on the parameters, $\\alpha$ and\n",
    "$\\beta$, we will define the Beta distribution in terms of $\\mu$ and\n",
    "$\\nu$. (The parameter, $\\nu$, is the concentration or precision of he\n",
    "Beta distribution.)\n",
    "\n",
    "The precision is an analog (not equal to) the inverse of the standard\n",
    "deviation; the larger the value of $\\nu$, the ***more** concentrated\n",
    "is the Beta distribution.\n",
    "\n",
    "In statistical notation our model is:\n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "\\mu \\sim Beta(\\alpha_{\\mu}, \\beta_{\\mu}) \\\\\n",
    "\\nu \\sim \\mathcal{HN(\\sigma_{\\nu})} \\\\\n",
    "\\sigma_{i} \\sim Beta(\\mu, \\nu) \\\\\n",
    "y_{i} \\sim Bernoulli(\\theta_{i})\n",
    "\\end{gather}\n",
    "$$\n",
    "\n",
    "We use the subscript $\\mathcal{i}$ to indicate that the model has\n",
    "groups with different values for some of the parameters. The following\n",
    "Kruschke diagrams show an additional level compared to the diagrams\n",
    "for the previous models.\n",
    "\n",
    "For this new model, we parameterize the Beta prior distribution in\n",
    "terms of $\\mu$ and $\\nu$ instead of $\\alpha$ and $\\beta$. This choice\n",
    "is common in Bayesian statistics. We make this choice because $\\mu$\n",
    "and $\\nu$ are more intuitive than $\\alpha$ and $\\beta$."
   ],
   "id": "122eec06b2fe9773"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's write the model in PyMC.\n",
    "with pm.Model() as model_h:\n",
    "    # hyperpriors\n",
    "    mu = pm.Beta('mu', 1, 1)\n",
    "    nu = pm.HalfNormal('nu', 10)\n",
    "\n",
    "    # prior\n",
    "    theta = pm.Beta('theta', mu=mu, nu=nu, shape=len(N_samples))\n",
    "\n",
    "    # likelihood\n",
    "    y = pm.Bernoulli('y', p = theta[group_idx], observed=data)\n",
    "\n",
    "    idata_h = pm.sample()"
   ],
   "id": "bcec007070bbc6b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Here are the Kruscke diagrams\n",
    "pm.model_to_graphviz(model_h)"
   ],
   "id": "b3e9f97abd6291b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "az.plot_trace(idata_h)\n",
    "plt.show()"
   ],
   "id": "4d8df29ce8f61908",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summary_g_18 = az.summary(idata_h)",
   "id": "e0788287dd10daf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "az.plot_posterior(idata_h)\n",
    "plt.show()"
   ],
   "id": "b6d833702f73c0dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.4 Shrinkage",
   "id": "91f76b4d9689276d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Please join me in a brief experiment:\n",
    "\n",
    "Repeat the previous model with slightly different data\n",
    "\n",
    "- One run setting all samples of `G_samples` to  18\n",
    "- One run setting all samples of `G_samples` to 3\n",
    "- One last run setting one element to 18 and the remaining two to three"
   ],
   "id": "5aa6c81bf96bd7ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "G_samples = [3, 3, 3] # number of good samples\n",
    "\n",
    "data = []\n",
    "for i in range(0, len(N_samples)):\n",
    "    data.extend(np.repeat([1, 0],\n",
    "                          [G_samples[i], N_samples[i] - G_samples[i]]))\n",
    "\n",
    "# Let's write the model in PyMC.\n",
    "with pm.Model() as model_h:\n",
    "    # hyperpriors\n",
    "    mu = pm.Beta('mu', 1, 1)\n",
    "    nu = pm.HalfNormal('nu', 10)\n",
    "\n",
    "    # prior\n",
    "    theta = pm.Beta('theta', mu=mu, nu=nu, shape=len(N_samples))\n",
    "\n",
    "    # likelihood\n",
    "    y = pm.Bernoulli('y', p = theta[group_idx], observed=data)\n",
    "\n",
    "    idata_h = pm.sample()"
   ],
   "id": "727b8210669b1e16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "az.plot_trace(idata_h)\n",
    "plt.show()"
   ],
   "id": "9544e623e9fa7fb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summary_g_3 = az.summary(idata_h)",
   "id": "58d00519c02c713a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "az.plot_posterior(idata_h)\n",
    "plt.show()"
   ],
   "id": "4b5b82dc6dee0c01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "G_samples = [18, 3, 3] # number of good samples\n",
    "\n",
    "data = []\n",
    "for i in range(0, len(N_samples)):\n",
    "    data.extend(np.repeat([1, 0],\n",
    "                          [G_samples[i], N_samples[i] - G_samples[i]]))\n",
    "\n",
    "# Let's write the model in PyMC.\n",
    "with pm.Model() as model_h:\n",
    "    # hyperpriors\n",
    "    mu = pm.Beta('mu', 1, 1)\n",
    "    nu = pm.HalfNormal('nu', 10)\n",
    "\n",
    "    # prior\n",
    "    theta = pm.Beta('theta', mu=mu, nu=nu, shape=len(N_samples))\n",
    "\n",
    "    # likelihood\n",
    "    y = pm.Bernoulli('y', p = theta[group_idx], observed=data)\n",
    "\n",
    "    idata_h = pm.sample()"
   ],
   "id": "ea4ad529d2c6199b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "az.plot_trace(idata_h)\n",
    "plt.show()"
   ],
   "id": "410668e62fdab3ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summary_g_mixed = az.summary(idata_h)",
   "id": "b5f2bd48f686316c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "az.plot_posterior(idata_h)\n",
    "plt.show()"
   ],
   "id": "55af8cbc47bbdfda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summary_g_18",
   "id": "9c6bfb52263b0abc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summary_g_3",
   "id": "8cfe56e69477a440",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summary_g_mixed",
   "id": "941f1be187ddaa9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If one compares $\\theta$ for each of our experiments, one observes\n",
    "\n",
    "- The three values of $\\theta$ for the first two experiments are almost equal\n",
    "- The three values of $\\theta$ for the last experiment is\n",
    "\n",
    "    - **Not** a mixture of the $\\theta$ values for the first\n",
    "      two experiments\n",
    "    - **But** an \"average\" of the $\\theta$ values for the first\n",
    "      two experiments\n",
    "\n",
    "This behavior is an example of the estimates shrinking toward the\n",
    "**common** mean (and not sampling from the other means). In other\n",
    "words, each group is informing all the other groups.\n"
   ],
   "id": "406df0a35bdbefec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Here is a plot of the posteriors for each prior\n",
    "posterior = az.extract(idata_h, num_samples=100)\n",
    "for sample in posterior[[\"mu\", \"nu\"]].to_array().values.T:\n",
    "    (pz.Beta(mu=sample[0], nu=sample[1]).\n",
    "     plot_pdf(legend='', color=\"C0\", alpha=0.1, support=(0.01, 0.99),\n",
    "              moments=\"m\"))\n",
    "\n",
    "(pz.Beta(mu=posterior[\"mu\"].mean().item(),\n",
    "         nu=posterior[\"nu\"].mean().item())\n",
    " .plot_pdf(legend='', color=\"C0\", moments=\"m\"))\n",
    "plt.xlabel('$θ_{prior}$')\n",
    "plt.show()"
   ],
   "id": "427920fa5c2a2638",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hmm... I think I've coded everything correctly, but I see a significantly\n",
    "different plot from the book. I do not understand the reason."
   ],
   "id": "3e30dde6492c2113"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Why is shrinkage desirable? It contributes to more stable inferences in\n",
    "a similar way that the Student's T distribution is more robust in the\n",
    "presence of outliers. Introducing hyperpriors results in a more\n",
    "conservative model; that is, a model that is **less** responsive\n",
    "to extreme values in individual groups.\n",
    "\n",
    "The amount of shrinkage depends on the data; a group with more data\n",
    "will \"pull\" the estimate of other groups \"harder\" than a group with\n",
    "fewer data points. If several groups are similar but one group is\n",
    "different, the similar groups informs the others of their similarity\n",
    "and reinforce a common estimate. At the same time, these similar groups\n",
    "\"pull\" the estimates for the less similar group toward the common mean."
   ],
   "id": "ded6f678e12be06f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Shrinkage**\n",
    "\n",
    "In a hierarchical model, groups that share a common hyperprior are\n",
    "effectively sharing information through the hyperprior. This \"sharing\"\n",
    "produces shrinkage; that is, individual group estimates of the mean\n",
    "are shrunk toward the common mean.\n",
    "\n",
    "By partially pooling the data, we are modeling groups as some middle\n",
    "ground between the groups being independent and a single big group."
   ],
   "id": "7630f3e9662e18c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nothing prevents us from building a hierarchical model with just\n",
    "two groups; however, we **prefer** to have **several** groups.\n",
    "Intuitively, getting shrinkage is like assuming each group is a\n",
    "single data point, and we are estimating the standard deviation\n",
    "at the group level. Just as we generally do not trust an estimate\n",
    "with too few data points without strong prior beliefs, we trust a\n",
    "hierarchical model with two few groups less than one with many groups."
   ],
   "id": "d25cc09834a7d46e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "14d1890f1f150cc5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
