{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Modeling with Lines",
   "id": "f315306e55934bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this chapter, we look at a common motif in statistics: **linear models**.\n",
    "\n",
    "This chapter will cover the following topics:\n",
    "\n",
    "- Simple linear regression\n",
    "- NegativeBinomial regression\n",
    "- Robust regression\n",
    "- Logistic regression\n",
    "- Variable variance\n",
    "- Hierarchical linear regression\n",
    "- Multiple linear regression\n"
   ],
   "id": "7a8af55da670c0ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1 Simple linear regression",
   "id": "37fea922a2a8c44f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Many problems in science, engineering, and business have a linear form.\n",
    "That is, we have a variable, $X$, and we want to model or predict a\n",
    "variable, $Y$, and the relationship between element of $X$ and $Y$\n",
    "is a **linear** relationship.\n",
    "\n",
    "In the simplest scenario, simple linear regression, both $X$ and $Y$\n",
    "are uni-dimensional continuous **random** variables.\n",
    "\n",
    "Typically, we use the following terminology:\n",
    "\n",
    "- $Y$ is the **dependent**, **predicted**, or **outcome** variable\n",
    "- $X$ is the **independent**, **predictor** or **input** variable\n",
    "\n",
    "Some typical situations where the linear regression model can be use are:\n",
    "\n",
    "- Model the relationship between soil salinity and crop productivity.\n",
    "Then answer questions like \"Is this relationship linear?\" or \"How\n",
    "strong is this relationship?\"\n",
    "- Find a relationship between the average chocolate consumption by\n",
    "country and the number of Nobel laureates in that country, and then\n",
    "understand why that relationship could be **spurious**.\n",
    "- Predict the gas bill (used for heating and cooking) of your house\n",
    "by using the solar radiation from the local weather report. How\n",
    "accurate is this prediction?"
   ],
   "id": "d9ea7f9cc3813661"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In _Chapter 2_, we saw the Normal model. We can think of this model\n",
    "as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mu &\\sim some\\ prior \\\\\n",
    "\\sigma &\\sim some\\ other\\ prior \\\\\n",
    "Y &\\sim \\mathcal{N}(\\mu, \\sigma)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The main idea of linear regression is to extend this model by adding\n",
    "a predictor variable $X$ to the estimation of mean, $\\mu$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\alpha &\\sim a\\ prior \\\\\n",
    "\\beta &\\sim another\\ prior \\\\\n",
    "\\sigma &\\sim some\\ other\\ prior \\\\\n",
    "\\mu &= \\alpha + \\beta X \\\\\n",
    "Y &\\sim \\mathcal{N}(\\mu, \\sigma)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This model says that a linear relationship exists between $X$\n",
    "and $Y$. However, that relationship is **not deterministic**\n",
    "because of the noise term, $\\sigma$.\n",
    "\n",
    "Additionally, this model states that the mean of $Y$ is a linear\n",
    "function of $X$ with **intercept** $\\alpha$ and **slope** $\\beta$.\n",
    "However, because we **do not know** the values of $\\alpha$, $\\beta$,\n",
    "or $\\sigma$, we set prior distributions over them."
   ],
   "id": "bd10fb9b5975a730"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Typically, when setting priors for linear models, we **assume** that\n",
    "the priors are **independent**. Because the priors are independent, we\n",
    "model the problem using three different priors instead of a single,\n",
    "joint prior.\n",
    "\n",
    "Additionally, because $\\sigma$ is a positive number, it is common\n",
    "to use the distribution:\n",
    "\n",
    "- HalfNormal\n",
    "- Exponential\n",
    "- HalfCauchy\n",
    "- And so on"
   ],
   "id": "9c56f107171d010c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The values for the intercept can vary widely from one problem to\n",
    "another and for different domains. In the experience of the author,\n",
    "\n",
    "- $\\alpha$ is usually centered around 0 and has a standard deviation\n",
    "no larger than 1\n",
    "- It is easier to have an informed prior for the slope, $\\beta$\n",
    "- For $\\sigma$, we can set it to a large value on the scale of $Y$\n",
    "For example, twice the value of its standard deviation.\n",
    "\n",
    "We should be cautious of using observed data to determine\n",
    "(\"guesstimate\") priors. It is usually fine to use the observed data\n",
    "if we want to avoid very restrictive priors; however, a more general\n",
    "principle is that if we don't have much knowledge of a parameter,\n",
    "it makes sense to ensure that our prior is **vague**.\n",
    "\n",
    "How do we make our priors more informative? We need to get informative\n",
    "priors from our **domain knowledge**."
   ],
   "id": "caf791f377ca27f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Extending the Normal Model**\n",
    "\n",
    "In summary, \"a linear regression model is an extension of the\n",
    "Normal model where the mean is computed as a linear function of a\n",
    "predictor variable.\""
   ],
   "id": "519b62d981036fb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.2 Linear bikes",
   "id": "c6d6f4979459527c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We now have a general idea of Bayesian linear models. Let's try\n",
    "to cement these ideas with an example.\n",
    "\n",
    "We have a record of temperatures and the number of bikes rented in a\n",
    "city. We want to model the relationship between temperature and the\n",
    "number of bikes rented.\n",
    "\n",
    "Here's a scatter plot of these two variables from the bike sharing\n",
    "dataset from the UCI Machine Learning Repository.\n",
    "\n",
    "The full dataset contains 17,379 records. Each record has 17 variables.\n",
    "\n",
    "We use a smaller dataset: 359 records and only two variables:\n",
    "`temperature` (in degrees Celsius) and `rented` (the number of\n",
    "rented bikes."
   ],
   "id": "ced43b333d0e0978"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Begin with our general imports\n",
    "import cytoolz.curried as ctc"
   ],
   "id": "925527e123468ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import our general data analysis tools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "id": "daf38c670753c80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import our SciPy tools\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from scipy.stats import linregress"
   ],
   "id": "c12971802e8271b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import PyMC and ancillary tools\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "import preliz as pz\n",
    "import xarray as xr"
   ],
   "id": "ef555d0b5512ddc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set values for plotting and for generating random variables\n",
    "az.style.use('arviz-grayscale')\n",
    "\n",
    "# Plotting defaults\n",
    "from cycler import cycler\n",
    "default_cycler = cycler(color=['#000000', '#6a6a6a', '#bebebe', '#2a2eec'])\n",
    "plt.rc('axes', prop_cycle=default_cycler)\n",
    "plt.rc('figure', dpi=300)\n",
    "\n",
    "# Set a random seed\n",
    "rng = np.random.default_rng(seed=123)"
   ],
   "id": "a077776ccac2b398",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's create a scatter plot of `rented` versus `temperature`.",
   "id": "b05cf1062964a4f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "bikes = pd.read_csv('./data/bikes.csv')\n",
    "bikes.plot(x='temperature', y='rented', figsize=(12, 3), kind='scatter')\n",
    "plt.show()"
   ],
   "id": "19ee35e149a85691",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "By \"squinting\", one can visualize a linear relationship between\n",
    "the number of bikes rented and outdoor temperature; however, we\n",
    "want to understand that relationship better.\n",
    "\n",
    "For our first model, we'll create a linear model using PyMC."
   ],
   "id": "7e6b57fa3f4c1de8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with pm.Model() as model_lb:\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=100) ## Very flat\n",
    "    beta = pm.Normal('beta', mu=0, sigma=10) ## Pretty flat\n",
    "    sigma = pm.HalfCauchy('sigma', 10)\n",
    "    mu = pm.Deterministic('mu', alpha + beta * bikes.temperature)\n",
    "    y_pred = pm.Normal('y_pred', mu=mu, sigma=sigma, observed=bikes.rented)\n",
    "    idata_lb = pm.sample()"
   ],
   "id": "899b6989cf3dbb28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here's a Kruschke diagram of a proposed model",
   "id": "e060e49075bd2bec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pm.model_to_graphviz(model_lb)",
   "id": "1aff956e57567bf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This model is like a Normal model; however, the mean is modeled\n",
    "as a **linear function** of the temperature. The intercept of the\n",
    "linear model is $\\alpha$, the slope of the linear model is $\\beta$,\n",
    "and the \"noise\" term is $\\sigma$.\n",
    "\n",
    "The new aspect to this model is that the model for $\\mu$ is\n",
    "**deterministic**; that is, given values for $\\alpha$ and $\\beta$\n",
    "(and our temperature data), the value for $\\mu$ is computed.\n",
    "\n",
    "This \"deterministic variable\" technique may seem useless; however,\n",
    "by defining this variable in our model (even though it is \"unnecessary\")\n",
    "we can include it in our `InferenceData` for later use. Notice that\n",
    "$\\mu$ is a vector with the same length as `bikes.temperature, which\n",
    "is the same number of records in the dataset."
   ],
   "id": "dfbe977d55630aa0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.2.1 Interpreting the posterior mean",
   "id": "fc05d7b0e35f33b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's generate a posterior plot but omit the deterministic variable,\n",
    "$\\mu$, because including it would generate one plot for each\n",
    "temperature value.\n",
    "\n",
    "To accomplish this goal, we can either explicitly list variables to\n",
    "include as values of the `var_names` parameter, or we can exclude\n",
    "a variable by prefacing the excluded variable by a tilde ('~')."
   ],
   "id": "535dabe15c2e4252"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "az.plot_posterior(idata_lb, var_names=['~mu'])\n",
    "plt.show()"
   ],
   "id": "8d55d07b83c40a83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If we read the means of each distribution, our equation for $\\mu$\n",
    "becomes $\\mu = 69 + 7.9 \\mathcal(X)$. In words, when the temperature\n",
    "is 0, the number of rented bikes is 69. For each degree above 0, the\n",
    "number of rented bikes increases by 7.9. Specifically, for a\n",
    "temperature of 28 C, we expect to see 278 bikes rented.\n",
    "\n",
    "This equation captures our expectations; however, we have uncertainty\n",
    "about the number of rented bikes because our value for $\\sigma$ has a\n",
    "mean value of 170. Consequently, even though we expect 278 bikes rented,\n",
    "our uncertainty means that we should not be surprised by renting\n",
    "anywhere from 100 to 500 bikes."
   ],
   "id": "dee58f4d56a5f4c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's create a few plots to help us visualize the combined uncertainty\n",
    "of these parameters. We'll start with two plots for the mean. Both\n",
    "curves plot the mean number of rented bikes as a function of\n",
    "temperature.\n",
    "\n",
    "The left panel takes 50 samples from the posterior and plots them as\n",
    "individual lines. The right panel takes **all** available posterior\n",
    "samples for $\\mu$ and uses them to compute the 94% HDI.\n"
   ],
   "id": "7ada042c9127001c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# From the book website\n",
    "posterior = az.extract(idata_lb, num_samples=50)\n",
    "x_plot = xr.DataArray(\n",
    "    np.linspace(bikes.temperature.min(), bikes.temperature.max(), 50),\n",
    "    dims='plot_id',\n",
    ")\n",
    "\n",
    "mean_line = posterior['alpha'].mean() + posterior['beta'].mean() * x_plot\n",
    "lines = posterior['alpha'] + posterior['beta'] * x_plot\n",
    "hdi_lines =az.hdi(idata_lb.posterior['mu'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "\n",
    "axes[0].plot(bikes.temperature, bikes.rented, 'C2.', zorder=-3)\n",
    "lines_ = axes[0].plot(x_plot, lines.T, c='C1', alpha=0.2, label='lines')\n",
    "plt.setp(lines_[1:], label='_')\n",
    "axes[0].plot(x_plot, mean_line, c='C0', label='mean line')\n",
    "axes[0].set_xlabel('temperature')\n",
    "axes[0].set_ylabel('rented bikes')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(bikes.temperature, bikes.rented, 'C2.', zorder=-3)\n",
    "idx = np.argsort(bikes.temperature.values)\n",
    "axes[1].fill_between(\n",
    "    bikes.temperature.values[idx],\n",
    "    hdi_lines['mu'][:, 0][idx],\n",
    "    hdi_lines['mu'][:, 1][idx],\n",
    "    color='C1',\n",
    "    label='HDI',\n",
    "    alpha=0.5,\n",
    ")\n",
    "axes[1].plot(x_plot, mean_line, c='C0', label='mean line')\n",
    "axes[1].set_xlabel('temperature')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "2bdbd9e967706ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "These plots essentially convey the same information. However, the\n",
    "left-hand plot represents uncertainty as a set of lines and the\n",
    "right-hand plot represents uncertainty as a shaded area.\n",
    "\n",
    "Notice that if you repeat the plots, you will get different lines\n",
    "because we are sampling from he posterior. The shaded area, in the\n",
    "right-hand plot, remains the same because we calculate the HDI from\n",
    "all available posterior samples.\n",
    "\n",
    "However, if we go further and refit the model, we will get new lines\n",
    "in the left-hand plot **and** we may get a different shaded region in\n",
    "the right-hand plot.\n",
    "\n",
    "The different between runs will probably be very small; if not, you\n",
    "may need to increase the number of drawn or there is something funny\n",
    "(an error) about your model and sampling. (See Chapter 10 for guidance.)"
   ],
   "id": "d7849aa80955f19f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We are showing these two plots to:\n",
    "\n",
    "- Illustrate different ways to represent uncertainty\n",
    "\n",
    "Which way is better? As frustrating as it is, \"It depends.\"\n",
    "\n",
    "The shaded area is:\n",
    "\n",
    "- A good option (and is very common)\n",
    "- Simple to compute\n",
    "- Simple to interpret\n",
    "\n",
    "But it **does not** show individual posterior samples.\n",
    "\n",
    "For example,\n",
    "\n",
    "|      |                                                   |\n",
    "|------|---------------------------------------------------|\n",
    "| If   | Most of the lines span a certain region           |\n",
    "| But  | A few lines have **very high** slopes             |\n",
    "| Then | The shaded HDI region could hide these exceptions |\n",
    "\n",
    "Finally, if you want to show individual samples from the posterior,\n",
    "it may be a good idea to animate them if you show theme in a\n",
    "presentation or a video.\n",
    "\n"
   ],
   "id": "8e45fb127cbcb7c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "These plots also illustrate different ways to extract information\n",
    "from the posterior. For example, the call to `az.extract()` takes\n",
    "the `chain` and `draw` values and stacks them in a single `sample`\n",
    "dimension. This stacking can be useful for later processings."
   ],
   "id": "b9e5a507159282f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The AI response to this question,\n",
    "\"what is stacking chain and draw dimensions pymc\", is:\n",
    "\n",
    "In PyMC, \"stacking chain and draw dimensions\" refers to the process\n",
    "of combining the \"chain\" dimension (representing different Markov\n",
    "Chain Monte Carlo (MCMC) chains) and the \"draw\" dimension (representing\n",
    "individual samples within each chain) into a single, flattened dimension,\n",
    "essentially creating a single array where each element corresponds to a\n",
    "single sample across all chains, effectively treating all chains as one\n",
    "large sample set.\n",
    "\n",
    "### Key points about stacking chain and draw dimensions: ###\n",
    "\n",
    "#### Purpose: ####\n",
    "\n",
    "This technique is often used when you want to analyze the posterior\n",
    "distribution without considering the individual chains, allowing\n",
    "for simpler data manipulation and visualization.\n",
    "\n",
    "#### Function in PyMC: ####\n",
    "\n",
    "To achieve this stacking, you can use the `arviz.InferenceData.stack`\n",
    "method, typically with arguments like `sample=(\"chain\", \"draw\")` to\n",
    "specify which dimensions should be combined.\n",
    "\n",
    "##### When to use it: #####\n",
    "\n",
    "- When comparing different models based on their posterior\n",
    "distributions without considering chain-specific variations.\n",
    "- When visualizing posterior distributions with plots that\n",
    "expect a single sample dimension.\n",
    "\n",
    "#### Important considerations: ####\n",
    "\n",
    "##### Convergence check: #####\n",
    "\n",
    "Before stacking chains, ensure that the chains have converged\n",
    "properly, as stacking can mask potential convergence issues.\n",
    "\n",
    "##### Alternative approaches: #####\n",
    "\n",
    "If you need to analyze chain-specific information, consider\n",
    "using methods that explicitly handle the chain dimension separately."
   ],
   "id": "b6799fd084b06c57"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Additionally, `num_samples` is used to ask for a subsample from the posterior.",
   "id": "359d93f1f2143e95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.2.2 Interpreting the posterior predictions",
   "id": "125caf6414df653f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We've seen haw we can sample from the posterior. But what if we want\n",
    "to make a **prediction**. For this purpose, we do posterior\n",
    "predictive sampling."
   ],
   "id": "d6426827c978a660"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sample from the posterior to make predictions and add these points\n",
    "# to our `InferenceData`.\n",
    "pm.sample_posterior_predictive(idata_lb, model=model_lb, extend_inferencedata=True)"
   ],
   "id": "313bcc046b75ea81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's plot our predictions. We'll include\n",
    "\n",
    "- The mean number of rented bikes (black line)\n",
    "- The central 505 range of rented bikes (dark gray band)\n",
    "- The central 94% of rented bikes (light gray band)\n",
    "\n",
    "Finally, notice that the posterior predictive samples predict\n",
    "a **negative** number of rented bikes for low temperatures. This\n",
    "result is a consequence of using the Normal distribution for the\n",
    "likelihood in `model_lb`. We could just cut out this \"invalid\"\n",
    "data; however, in the next section, we'll see how we can easily\n",
    "improve this model to avoid nonsensical predictions."
   ],
   "id": "8dbbde8cf1eff00f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot our predictions\n",
    "mean_line = idata_lb.posterior['mu'].mean(('chain', 'draw'))\n",
    "temperatures = np.random.normal(bikes.temperature.values, 0.01)\n",
    "idx = np.argsort(temperatures)\n",
    "\n",
    "x = np.linspace(temperatures.min(), temperatures.max(), 15)\n",
    "y_pred_q = (\n",
    "    idata_lb.posterior_predictive['y_pred']\n",
    "            .quantile([0.03, 0.97, 0.25, 0.75], dim=['chain', 'draw'])\n",
    ")\n",
    "y_hat_bounds = iter(\n",
    "    [PchipInterpolator(temperatures[idx], y_pred_q[i][idx])(x)\n",
    "     for i in range(4)]\n",
    ")\n",
    "\n",
    "_, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(bikes.temperature, bikes.rented, 'C2.', zorder=-3)\n",
    "ax.plot(bikes.temperature[idx], mean_line[idx], c='C0')\n",
    "\n",
    "for lb, ub in zip(y_hat_bounds, y_hat_bounds):\n",
    "    ax.fill_between(x, lb, ub, color='C1', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('temperature')\n",
    "ax.set_ylabel('rented bikes')\n",
    "\n",
    "plt.show()"
   ],
   "id": "ae49809535b43d41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1a4a8408809c57e5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
